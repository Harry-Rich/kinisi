{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62aac6f-f4dd-46f6-8b2d-c092d3b6bf38",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "The aim of investigating the mean-squared displacements as a function of timestep is to fit a straight line and therefore obtain a estimate of the infinite timescale diffusion coefficient. \n",
    "This might seem like a straight forward concept, however, for a real simulation, with a limited number of atoms and simulation length, the observed value of the diffusion coefficient will vary upon repetition of a given simulation.\n",
    "`kinisi` is a Python library that is capable of: \n",
    "<ol>\n",
    "<li> Accurately estimating the infinite timescale diffusion coefficient from a single simulation</li>\n",
    "<li> Quantifying the variance in the diffusion coefficient that would be observed on repetition of the simulation</li>\n",
    "</ol>\n",
    "\n",
    "In order to achieve this, it is neccessary to build up a complete picture of the observed diffusion from the simulation and use this information to apply the approach with the highest [statistical efficiency](https://en.wikipedia.org/wiki/Efficiency_(statistics)) to estimate the diffusion coefficient. \n",
    "The different approach that can be taken to estimate this are shown in the schematic below, which we will work through below. \n",
    "\n",
    "<center>\n",
    "<img src=\"_static/schematic_kinisi.pdf\" alt=\"A schematic showing the different possibilities for the analysis of diffusion processes by mean-squared displacement.\" width=\"750px\"></img>\n",
    "</center>\n",
    "<center>\n",
    "A schematic of the process of diffusion coefficient determination, where the process used in `kinisi` is identified with the pink box.\n",
    "</center>\n",
    "\n",
    "## Finding the mean-squared displacement\n",
    "\n",
    "Consider first the displacements that we calculate from an atomic simulation. \n",
    "We have performed a simulation of lithium lanthanum zirconium oxide (LLZO) to use as an example, we will consider initially the displacements, $\\mathbf{x}$, that occur in 2.1 ps of simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849431d-372b-444b-8d36-39b4b0edb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import pinvh\n",
    "from sklearn.utils import resample\n",
    "from emcee import EnsembleSampler\n",
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a4384-9419-490b-896c-2277c452116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements = np.load('_static/displacements.npz')['disp']\n",
    "\n",
    "print('Displacements shape', displacements.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91522a3-7c5a-45c8-91b7-642c759646e8",
   "metadata": {},
   "source": [
    "We can see that for this timestep, the `displacements` array has a shape of `(192, 119, 3)` this means that there are 192 atoms, each observed 119 times (i.e. in the whole simulation there 119 times that 2.1 ps of simulation is present), for 3 dimensions. \n",
    "Let us now visualise the probability distribution for the displacements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5db898-0ff1-4e5b-b4b8-2ef45024776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(displacements.flatten(), bins=50, density=True)\n",
    "plt.xlabel('$\\mathbf{x}(2.1\\;\\mathrm{ps})$')\n",
    "plt.ylabel('$p[\\mathbf{x}(2.1\\;\\mathrm{ps})]$')\n",
    "plt.xlim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56eb2f-a3e3-4555-8ee7-90c1da3546f3",
   "metadata": {},
   "source": [
    "The ordinate axis in the fitting of the Einstein equation is the mean of the squared displacements, $\\mathbf{r}^2$, therefore we must square these displacements and determine the total displacement over all dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fb7d4-f763-401f-b7f8-92ee350de79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_displacements = np.sum(displacements ** 2, axis=2).flatten()\n",
    "\n",
    "plt.hist(sq_displacements, bins=50, density=True)\n",
    "plt.xlabel('$\\mathbf{s}^2$')\n",
    "plt.ylabel('$p(\\mathbf{s}^2)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46553b73-e8ba-4534-bc28-26e7ea8721a2",
   "metadata": {},
   "source": [
    "The mean of these squared displacements, $\\langle\\mathbf{r}^2\\rangle$, can be found as the numerical mean.\n",
    "Below, the mean is shown as a black vertical line over the histogram of the squared displacements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e3974-8041-457c-b4b9-9ae0a7dab794",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd = np.mean(sq_displacements)\n",
    "\n",
    "print(f'MSD = {msd:.3f}')\n",
    "\n",
    "plt.hist(sq_displacements, bins=50, density=True)\n",
    "plt.axvline(msd, color='k')\n",
    "plt.xlabel('$\\mathbf{s}^2$')\n",
    "plt.ylabel('$p(\\mathbf{s}^2)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87201c0f-48bb-4c65-bdac-82f22296271f",
   "metadata": {},
   "source": [
    "Therefore, if we perform this operation at a series of different timesteps (the *x*-axis in the diffusion relation), we can populate the *y*-axis for our dataset. \n",
    "This is shown for the LLZO material below (note that throughout this description we focus on data in the diffusive regime alone). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf0ee3-7310-4922-8bbf-da88aada579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, msd = np.loadtxt('_static/msd.txt')\n",
    "\n",
    "plt.plot(dt, msd)\n",
    "plt.ylabel('MSD/Å$^2$')\n",
    "plt.xlabel('$\\Delta t$/ps')\n",
    "plt.xlim(0, 14.5)\n",
    "plt.ylim(0, 12.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bbfa07-9221-4a64-b235-33e3c60fde50",
   "metadata": {},
   "source": [
    "The first thing we notice is that this data has no uncertainty associated with it. \n",
    "Given that this simulation is of a finite size, this is impossible. \n",
    "Consider, if we run another independent simulation of the same system, we will probably get different MSD plots. \n",
    "\n",
    "## Finding the uncertainty in the mean-squared displacement\n",
    "\n",
    "It is possible to use [bootstrap mean resampling](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) to determine the distribution of the mean-squared displacement. \n",
    "If the observed distribution is an accurate description of the true distribution, then bootstrap mean resampling is analogous to performing multiple observed of some subset of the true distribution. \n",
    "However, in order to accurately determine the distribution of mean-squared displacement, then we must resample *only* independent trajectories.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Thought experiment\n",
    "    \n",
    "Consider a particle traveling on a one-dimensional random walk for 9 steps, the trajectory that describes the displacement between the initial and 5th positions will be highly correlated with that between the 2nd and 6th positions, given that 4 of these steps are identical. However, the trajectory between the 5th and final positions will be completely independent as there is no identical steps.\n",
    "\n",
    "</div>\n",
    "\n",
    "Given that the total LLZO simulation is only around 14 ps, it is not posssible for there to be 119 non-overlapping trajectories of 2.1 ps (2.1 ps × 119 = 249.9 ps, much more than our simulation), therefore some of the observations must be overlapping. \n",
    "The work of [Smith & Gillan](ftp://ftp.daresbury.ac.uk/ccp5.newsletter/45/ps/smith.ps.gz) outlines an equation to determine the maximum number of independent trajectories, $N_i(\\Delta t)$, as a function of timestep, \n",
    "\n",
    "$$\n",
    "N_i(\\Delta t) =  N_{\\mathrm{atoms}}(\\Delta t)\\left\\lfloor\\frac{N_{\\mathrm{obs}}(0)}{N_{\\mathrm{obs}}(0) - N_{\\mathrm{obs}}(\\Delta t) + 1}\\right\\rfloor,\n",
    "$$\n",
    "\n",
    "where $N_{\\mathrm{obs}}(\\Delta t)$ is the maximum number of displacement observations per atom and $N_{\\mathrm{atoms}}(\\Delta t)$ is the number of atoms, at a given timestep, $\\Delta t$.\n",
    "We can determine this for the displacements above, by obtaining also the shape of the displacements array at the shortest timestep.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2259f23-5c4e-46f4-9dba-7d8e7e09a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements0 = np.load('_static/displacements.npz')['disp0']\n",
    "\n",
    "N_i = displacements.shape[0] * int(\n",
    "    displacements0.shape[1] / (displacements0.shape[1] - displacements.shape[1] + 1))\n",
    "print('Maximum number of independent trajectories', N_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75185f-a551-4402-a0f2-c108298f974d",
   "metadata": {},
   "source": [
    "Therefore, when we perform the bootstrap mean resampling at this timestep, with each iteration we should draw only 1152 samples from the distribution of the squared displacements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40501211-11e5-48fd-baac-978911b3536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_resample(samples: np.ndarray, n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform the bootstrap mean resampling for 10000 iterations.\n",
    "    \n",
    "    :param samples: Distribution to resample.\n",
    "    :param n: Number of samples to draw each iteration. \n",
    "    :return: Distribution of mean. \n",
    "    \"\"\"\n",
    "    return np.array([np.mean(resample(samples, n_samples=n)) for j in range(10000)])\n",
    "\n",
    "resampled_msd = mean_resample(sq_displacements, N_i)\n",
    "\n",
    "plt.hist(resampled_msd, bins=50, density=True)\n",
    "plt.xlabel(r'$\\langle\\mathbf{s}^2\\rangle$')\n",
    "plt.ylabel(r'$p(\\langle\\mathbf{s}^2\\rangle)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458dffd-5d69-4e4f-927d-51a6bf6444e0",
   "metadata": {},
   "source": [
    "It is clear now that, from this bootstrap mean resampling, we have a distribution of mean-squared displacements (which are normally distributed). \n",
    "From this, we can find the mean and standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95f08a-564d-4d79-8a0f-013f714a0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSD = {resampled_msd.mean():.3f}+\\-{resampled_msd.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792f6b3-e6e2-420a-8488-8da6c880d3e0",
   "metadata": {},
   "source": [
    "The value of the MSD is very similar (within sampling error) to that determined as the numerical mean of the squared displacements. \n",
    "However, now we have information about the distribution of the mean-squared displacement and we can visualise this for a real material below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaed7eb-f653-47f6-955b-b38a7098003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, msd, msd_std = np.loadtxt('_static/msd_std.txt')\n",
    "\n",
    "plt.errorbar(dt, msd, msd_std)\n",
    "plt.ylabel('MSD/Å$^2$')\n",
    "plt.xlabel('$\\Delta t$/ps')\n",
    "plt.xlim(0, 14.5)\n",
    "plt.ylim(0, 13.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868e905-04a2-45bb-908f-e63a791341b4",
   "metadata": {},
   "source": [
    "## Understanding the correlation between measurements\n",
    "\n",
    "However, the knowledge of the distribution of mean-squared displacements does not completely describe the variance in the data set.  \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Thought experiment\n",
    "    \n",
    "Consider, a particle travelling on a one-dimensional random walk with a step size of 1 Å.\n",
    "If, after 10 steps, the particle has been displaced by 5 Å then after 11 steps the particle could only be displaced by either 4 Å or 6 Å and after 12 steps the particle could only be displaced by 3, 4, 5, 6, 7 Å. \n",
    "</div>\n",
    "\n",
    "This fact results in a substantial [correlation](https://en.wikipedia.org/wiki/Correlation) between the distributions of mean-squared displacement at different timesteps. \n",
    "To quantify this correlation, we have derived an approach to <a href='./_static/derivation.pdf'>estimate the full covariance matrix</a> (a description of the correlation between the timesteps). \n",
    "The result of this derivation is that the covariance between two timesteps, $\\mathrm{cov}_i\\Big(\\big\\langle \\mathbf{r}^2(\\Delta t_n) \\big\\rangle, \\big\\langle \\mathbf{r}^2(\\Delta t_{n+m}) \\big\\rangle\\Big)$, is the product of the variance at the first timestep, $\\Delta t_n$ and the ratio of maximum independent trajectories at each timestep,\n",
    "\n",
    "$$\n",
    "\\mathrm{cov}\\Big(\\big\\langle \\mathbf{r}^2(\\Delta t_n) \\big\\rangle, \\big\\langle \\mathbf{r}^2(\\Delta t_{n+m}) \\big\\rangle\\Big) = \\sigma^2\\big(\\langle \\mathbf{r}^2(\\Delta t_n) \\rangle\\big) \\frac{N_i(\\Delta t_{n})}{N_i(\\Delta t_{n+m})},\n",
    "$$\n",
    "\n",
    "This approach is extremely computationally efficient, as there is no additional sampling required to determine this estimate of the full covariance matrix. \n",
    "This is shown in our LLZO simulation in the figure below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc83c3f-c6c7-442c-b190-4daa0d01c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('_static/cov.npz')\n",
    "dt = data['dt']\n",
    "cov = data['cov']\n",
    "\n",
    "plt.subplots(figsize=(6, 4.9))\n",
    "plt.contourf(*np.meshgrid(dt, dt), cov, levels=20)\n",
    "plt.xlabel('$\\Delta t_n$/ps')\n",
    "plt.ylabel('$\\Delta t_{n+m}$/ps')\n",
    "plt.axis('equal')\n",
    "plt.colorbar(label=r'$\\mathrm{cov}' + \n",
    "             r'(\\langle \\mathbf{s}^2(\\Delta t_n) \\rangle, ' + \n",
    "             r'\\langle \\mathbf{s}^2(\\Delta t_{n+m}) \\rangle)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bf34d-d199-4dc3-959b-67dc58905c2b",
   "metadata": {},
   "source": [
    "## Modelling a Gaussian process\n",
    "\n",
    "The determination of the variance in the mean-squared displacement and estimation of the full covariance matrix allows the mean-squared displacement to be described as a covariant [Gaussian process](https://en.wikipedia.org/wiki/Gaussian_process), and therefore we can define it with a `scipy.stats.multivariate_normal` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758f623-06e9-4750-ba82-02d5fdab059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = multivariate_normal(mean=msd, cov=cov, allow_singular=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e558b-1922-4b73-b212-edec14909c21",
   "metadata": {},
   "source": [
    "This object, in theory, allows us to simulate potential trajectories that could be observed in our simulation were repeated. \n",
    "In the plot below, we compare such a simulation from the Gaussian process produced from the full covariance matrix with that produced when there only the diagonal terms are defined (i.e. only the variances for each mean-squared displacement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e8811-2820-4b0e-b403-4857b1c66584",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_wls = multivariate_normal(\n",
    "    mean=msd, cov=np.diag(cov.diagonal()), allow_singular=True)\n",
    "\n",
    "plt.plot(dt, gp.rvs(1).T, label='GLS')\n",
    "plt.plot(dt, gp_wls.rvs(1).T, label='WLS')\n",
    "plt.legend()\n",
    "plt.ylabel('MSD/Å$^2$')\n",
    "plt.xlabel('$\\Delta t$/ps')\n",
    "plt.xlim(0, 14.5)\n",
    "plt.ylim(0, 14.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38682818-57c4-4955-96c2-fda52769c6f4",
   "metadata": {},
   "source": [
    "The erratic changes in the mean-squared displacement that is observed in the plot with only the variances defined are unphysical when we consider the correlation thought experiment above. \n",
    "\n",
    "## Sampling a Gaussian process\n",
    "\n",
    "As mentioned above, this process aims to determine the diffusion coefficient and ordinate offset, and their model variance, by fitting the Einstein relation. \n",
    "In `kinisi`, we take some number of random samples (below we take 32000) from our Gaussian process and determine the gradient and intercept of the straight line fitted to each sample by a [generalised least squares](https://en.wikipedia.org/wiki/Generalized_least_squares) approach, using the covariance matrix described above. \n",
    "This is analogous to preforming multiple measurements of the diffusion process and finding the gradient and intercept from fitting a straight line to each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35f746-2b61-4dd9-966a-65676978238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([dt, np.ones_like(dt)]).T\n",
    "Y = gp.rvs(32000).T \n",
    "inv_cov = pinvh(cov)\n",
    "\n",
    "flatchain = np.matmul(np.matmul(np.linalg.pinv(np.matmul(X.T, np.matmul(inv_cov, X))), X.T), np.matmul(inv_cov, Y)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c9424-5f6f-4e05-afe2-b232dd476126",
   "metadata": {},
   "source": [
    "The diffusion coefficient (in units of cm<sup>2</sup>s<sup>-1</sup>) is found by dividing the gradient by 60000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150d420-8fd1-441b-bb7b-8fa7187ede2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatchain[:, 0] /= 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a46948-730d-483f-a60a-271d90697d2c",
   "metadata": {},
   "source": [
    "We can then visualise these samples as a `corner` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67ae0d-0132-4ce4-9cac-f9442f774157",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(flatchain, labels=['$D$/cm$^2$s$^{-1}$', '$D_{\\mathrm{offset}}$/Å$^2$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f0785-b628-47cf-88cd-74776c314019",
   "metadata": {},
   "source": [
    "It is also possible to visualise this as a traditional mean-squared displacement plot with a probability distribution of the Einstein relation values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e5df7-e33a-4348-95ba-b63cbcde5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(dt, msd, msd_std)\n",
    "for i in np.random.randint(flatchain.shape[0], size=128):\n",
    "    plt.plot(\n",
    "        dt, flatchain[i, 0] * 60000 * dt + flatchain[i, 1], \n",
    "        color='k', alpha=0.05, zorder=10)\n",
    "plt.ylabel('MSD/Å$^2$')\n",
    "plt.xlabel('$\\Delta t$/ps')\n",
    "plt.xlim(0, 14.5)\n",
    "plt.ylim(0, 14.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
