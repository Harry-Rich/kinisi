% Define document class
\documentclass[reprint,superscriptaddress,nobibnotes,amsmath,amssymb,aps,onecolumn]{revtex4-2}

% Import relevant packages
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage[separate-uncertainty=true]{siunitx}
\usepackage{amsmath}
\usepackage[shortlabels]{enumitem}
\usepackage{xfrac}
\usepackage{mhchem}
\usepackage{blindtext}
\sisetup{
    list-units      = brackets,
    range-units     = brackets,
    range-phrase    = -,
    list-pair-separator= {, },
    list-separator  = {, },
    list-final-separator = {, },
    % list-exponents = combine-bracket , 
    % product-exponents = combine-bracket , 
    % range-exponents = individual
    }

% Begin!
\begin{document}

% Title
\title{Uncertainties and covariances in an analytical random walk}

% Author list
\author{Andrew R. McCluskey}
  \email{andrew.mccluskey@ess.eu}
  \email{a.r.mccluskey@bath.ac.uk}
  \affiliation{European Spallation Source ERIC, P.O. Box 176, SE-221 00, Lund, Sweden}
  \affiliation{Department of Chemistry, University of Bath, Claverton Down, Bath, BA2 7AY, UK}

\maketitle 

\section{Variances in an analytical random walk}
\label{sec:ran}

Here, we derive the variance on the mean-squared displacement (MSD) of random walk, clarifying some aspects from the work of Smith and Gillan \cite{smith_random_1996}.
We will consider a single particle, travelling in \num{1} dimension over time.
The particle is displaced by $h = \pm d_{1}$ (where the subscript \num{1} is indicative of the dimensionality of the system) in a single hop, where the hops are proportional to the timestep that has elapsed.
The MSD of this particle, after $n$ hops, can be described with the following,
%
\begin{equation}
    \begin{aligned}
        \langle \mathbf{r}_1^2(n) \rangle & = \Bigg\langle \bigg[ \sum_{i=1}^{n} h_i \bigg]^2 \Bigg\rangle = \Bigg\langle \sum_{i=1}^{n} \sum_{j=1}^{n} h_i h_j \Bigg\rangle = \Bigg\langle \sum_{i=1}^{n} h_i^2 \Bigg\rangle + \Bigg\langle \sum_{i=1}^{n} \sum_{j \neq i}^{n} h_i h_j \Bigg\rangle \\
        & = \sum_{i=1}^{n} \big\langle h_i^2 \big\rangle + \sum_{i=1}^{n} \sum_{j \neq i}^{n} \big\langle h_i h_j \big\rangle = n d_1^2.
    \end{aligned}
\end{equation}
%
In the fourth line above, the cross term double summation (where $j \neq i$) is equal to zero, as the product of $h(i)h(j)$ is $d_1^2$ and therefore has equal probability of being \num{+1} and \num{-1} so the average must be zero.
This  shows the linear relationship between timestep and displacement.

The determination of the MSD allows for the derivation of the variance, $\sigma_1^2(n)$ of the MSD for each timestep.
This variance can be found with the standard statistical formula,
%
\begin{equation}
    \sigma_1^2\big(\mathbf{r}_1^2(n)\big) = \bigg\langle \Big[ \mathbf{r}_1^2(n) - \big\langle \mathbf{r}_1^2(n) \big\rangle \Big] ^ 2 \bigg\rangle,
\end{equation}
%
which may be expanded and reformulated as,
%
\begin{equation}
    \sigma_1^2\big(\mathbf{r}_1^2(n)\big) = \Big\langle \big[ \mathbf{r}_1^2(n) \big] ^ 2 \Big\rangle - 2 \Big\langle \mathbf{r}_1^2(n) \Big\rangle \Big\langle \mathbf{r}_1^2(n) \Big\rangle + \Big\langle \mathbf{r}_1^2(n) \Big\rangle ^2 = \Big\langle \mathbf{r}_1^4(n) \Big\rangle - \Big\langle \mathbf{r}_1^2(n) \Big\rangle ^2,
    \label{equ:exp}
\end{equation}
%
where,
%
\begin{equation}
    \Big\langle \mathbf{r}_1^2(n) \Big\rangle ^2 = \big(n d_1^2\big) ^2
    \label{equ:smsd}
\end{equation}
%
and,
%
\begin{equation}
    \Big\langle \mathbf{r}_1^4(n) \Big\rangle = \Bigg\langle \sum_{i=1}^{n} \sum_{j=1}^{n} \sum_{k=1}^{n} \sum_{l=1}^{n} h_ih_jh_kh_l \Bigg\rangle.
    \label{equ:h4}
\end{equation}
%
The term on the right-hand side of Equation~\ref{equ:h4} can be simplified substantially, as the four displacements are only uncorrelated when $i \neq j \neq k \neq l$.
This leads to four possible conditions that will survive the averaging process,
%
\begin{enumerate}[(a)]
    \item $i = j = k = l$,
    \item $(i = j) \neq (k = l)$,
    \item $(i = k) \neq (j = l)$,
    \item $(i = l) \neq (j = k)$,
\end{enumerate}
%
these conditions will ensure a positive product for $h_ih_jh_kh_l$, additionally, the conditions (b), (c) and (d) are equivalent.
The result from (a) will be,
%
\begin{equation}
    \Bigg\langle \sum_{i=1}^{n} h_i^4 \Bigg\rangle = n d_1^4,
\end{equation}
%
while from (b), (c), and (d) the following is obtained,
%
\begin{equation}
    \Bigg\langle \sum_{i=1}^{n} \sum_{j=1}^{n} h_i^2 h_j^2 \Bigg\rangle = \big(n d_1^2\big)^2.
\end{equation}
%
This allows Equation~\ref{equ:h4} to be rewritten as,
%
\begin{equation}
    \Big\langle \mathbf{r}_1^4(n) \Big\rangle = nd^4 + 3\Big[\big(nd^2\big)^2\Big] = nd_1^4 + 3n^2d_1^4 = (3n^2 + n) d_1^4,
\end{equation}
%
as $n \to \infty$,
\begin{equation}
    \Big\langle \mathbf{r}_1^4(n) \Big\rangle \to 3n^2d_1^4.
    \label{equ:r4}
\end{equation}
%
This means that by combining this with Equation~\ref{equ:smsd} the variance can be determined as,
%
\begin{equation}
    \sigma_1^2\big(\mathbf{r}_1^2(n)\big) = 3n^2d_1^4 - n^2 d_1^4 = 2n^2d_1^4.
\end{equation}
%
From this result, the variance, $\delta(n) ^ 2$, over many \emph{independent} particles, $N_i(n)$, can be found as,
%
\begin{equation}
    \sigma_{1,i}^2\big(\mathbf{r}_{1,i}^2(n)\big) = \frac{2}{N_i(n)}n^2d_1^4.
\end{equation}
%
To convert these one-dimensional results into three-dimensional results (we note that this conversion is generalisable to $\nu$-dimensions), we multiply both the MSD and its variance by \num{3}.
Then, we must consider $d_3$, which is the sum of three, orthogonal random walks in the $x$-, $y$-, and $z$-directions, so on average is $\sqrt{\langle d_x^2 \rangle + \langle d_y^2 \rangle + \langle d_z^2 \rangle}$ so $1/(\sqrt{3})d_3 = d_1$, therefore,
%
\begin{equation}
    \langle \mathbf{r}_3^2(n) \rangle = 3nd_1^2 = 3n\bigg(\frac{1}{\sqrt{3}}d_3\bigg)^2 = n d_3^2,
\end{equation}
%
and,
%
\begin{equation}
    \sigma_3^2\big(\mathbf{r}_{3}^2(n)\big) = 3(2n^2d_1^4)  = 3\Bigg(2n^2 \bigg(\frac{1}{\sqrt{3}}d_3\bigg)^4\Bigg) = 3\bigg(\frac{2n^2d_3^4}{9}\bigg) = \frac{2n^2d_3^4}{3}.
\end{equation}
%
Therefore the result over $N$ \emph{independent} trajectories is,
%
\begin{equation}
    \sigma_{3,i}^2\big(\mathbf{r}_{3,i}^2(n)\big) = \frac{2n^2d_3^4}{3N_i(n)}.
\end{equation}
%
where $N_i$ is the sample size,
%
\begin{equation}
    N_i(\Delta t) =  N_{\mathrm{atoms}}(\Delta t)\left\lfloor\frac{N_{\mathrm{obs}}(0)}{N_{\mathrm{obs}}(0) - N_{\mathrm{obs}}(\Delta t) + 1}\right\rfloor,
    \label{equ:samples}
\end{equation}
%.

\section{Extension to covariance matrix}

Above, it is has been shown how the variance of an MSD after a given number of steps can be defined.
Now, we will extend this derivation to show how the covariance is defined similarly. 
Let's consider two MSD values, after $i$ steps and $i+j$ steps, 
%
\begin{equation}
    \begin{aligned}
        \big\langle \mathbf{r}_1^2(n) \big\rangle & = nd_1^2 \\
        \big\langle \mathbf{r}_1^2(n+m) \big\rangle & = (n+m)d_1^2 \\ 
    \end{aligned}
\end{equation}
%
The covariance between these values is defined as, 
%
\begin{equation}
    \mathrm{cov}\Big(\big\langle \mathbf{r}_1^2(n) \big\rangle, \big\langle \mathbf{r}_1^2(n+m) \big\rangle\Big) = \Big\langle [\mathbf{r}_1^2(n) - \langle \mathbf{r}_1^2(n)\rangle][\mathbf{r}_1^2(n+m) - \langle \mathbf{r}_1^2(n+m)\rangle] \Big\rangle,
\end{equation}
%
which can be expanded and reformulated, 
%
\begin{equation}
    \begin{aligned}
        \mathrm{cov}\Big(\big\langle \mathbf{r}_1^2(n) \big\rangle, \big\langle \mathbf{r}_1^2(n+m) \big\rangle\Big) & = \Big\langle \mathbf{r}_1^2(n) \mathbf{r}_1^2(n+m)  - \mathbf{r}_1^2(n) \langle \mathbf{r}_1^2(n+m) \rangle - \mathbf{r}_1^2(n+m) \langle \mathbf{r}_1^2(n) \rangle + \langle \mathbf{r}_1^2(n) \rangle \langle \mathbf{r}_1^2(n+m) \rangle \Big\rangle \\ 
        & = \langle \mathbf{r}_1^2(n) \mathbf{r}_1^2(n+m) \rangle - \langle \mathbf{r}_1^2(n) \rangle \langle \mathbf{r}_1^2(n+m) \rangle,
    \end{aligned}
    \label{equ:covl}
\end{equation}
%
where, 
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n) \big\rangle \big\langle \mathbf{r}_1^2(n+m) \big\rangle = nd^2(n+m)d^2 = n(n+m)d^4,
\end{equation}
%
and by analogy to Equation~\ref{equ:h4}, 
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = \Bigg\langle \sum_{i=1}^n \sum_{j=1}^n \sum_{k=1}^{n+m} \sum_{l=1}^{n+m} h_i  h_j h_k h_l \Bigg\rangle, 
\end{equation}
%
which we will rewrite as, 
%
\begin{equation}
    \begin{aligned}
        \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = \Bigg\langle & \sum_{i=1}^n \sum_{j=1}^n \sum_{k=1}^n \sum_{l=1}^n h_i  h_j h_k h_l + \sum_{i=1}^n \sum_{j=1}^n \sum_{k=1}^n \sum_{l=n+1}^{n+m} h_i  h_j h_k h_l \\ 
        & + \sum_{i=1}^n \sum_{j=1}^n \sum_{k=n+1}^{n+m} \sum_{l=1}^n h_i  h_j h_k h_l + \sum_{i=1}^n \sum_{j=1}^n \sum_{k=n+1}^{n+m} \sum_{l=n+1}^{n+m} h_i  h_j h_k h_l \Bigg\rangle.
    \end{aligned}
    \label{equ:bigcov}
\end{equation}
%
The second and third terms in Equation~\ref{equ:bigcov} tend to \num{0} due to the equal probability of positive and negative displacements, reducing to, 
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = \Bigg\langle \sum_{i=1}^n \sum_{j=1}^n \sum_{k=1}^n \sum_{l=1}^n h_i  h_j h_k h_l \Bigg\rangle + \Bigg\langle \sum_{i=1}^n \sum_{j=1}^n \sum_{k=n+1}^{n+m} \sum_{l=n+1}^{n+m} h_i  h_j h_k h_l \Bigg\rangle,
\end{equation}
%
and using Equation~\ref{equ:r4} gives, 
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = 3n^2d_1^4 + \Bigg\langle \sum_{i=1}^n \sum_{j=1}^n \sum_{k=n+1}^{n+m} \sum_{l=n+1}^{n+m} h_i  h_j h_k h_l \Bigg\rangle.
\end{equation}
%
Finally, we rewrite the above as, 
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = 3n^2d_1^4 + \Bigg\langle \sum_{i=1}^n \sum_{j=1}^n h_i h_j \Bigg\rangle \Bigg\langle \sum_{k=n+1}^{n+m} \sum_{l=n+1}^{n+m} h_k h_l \Bigg\rangle,
\end{equation}
%
where the following holds,
%
\begin{equation}
    \big\langle \mathbf{r}_1^2(n)  \mathbf{r}_1^2(n+m) \big\rangle = 3n^2d_1^4 + nd^2md^2 =  3n^2d_1^4 + nmd_1^4.
\end{equation}
%
Putting this result into Equation~\ref{equ:covl} allows the covariance to be written as, 
%
\begin{equation}
    \mathrm{cov}\Big(\big\langle \mathbf{r}_1^2(n) \big\rangle, \big\langle \mathbf{r}_1^2(n+m) \big\rangle\Big) = 3 n^2 d_1^4 + nmd_1^4 - n(n+m)d_1^4 = 3 n^2 d_1^4 - n^2d_1^4 = 2n^2d_1^4,
\end{equation}
%
indicating that the covariance depends only on the number of overlapping points, $n$. 
This can be rationalised as the steps are random and therefore for any non-overlapping points the covariance must be \num{0}.
However, the difference between the variance and the covariance becomes clear when we consider the number of \emph{independent} trajectories to consider, which for the covariance is,
%
\begin{equation}
    \mathrm{cov}_{1,i}\Big(\big\langle \mathbf{r}_1^2(n) \big\rangle, \big\langle \mathbf{r}_1^2(n+m) \big\rangle\Big) = \frac{2}{N_i(n+m)}n^2d_1^4,
\end{equation}
%
since $N_i(n+m)$ is the minimum number of \emph{independent} trajectories in both $n$ and $n+m$. 
This result extends to three-dimensions identically to the self-timestep uncertainty to give the following for \emph{independent} trajectories, 
%
\begin{equation}
    \mathrm{cov}_{3,i}\Big(\big\langle \mathbf{r}_3^2(n) \big\rangle, \big\langle \mathbf{r}_3^2(n+m) \big\rangle\Big) = \frac{2n^2d_3^4}{3N_i(n+m)}
    \label{equ:icov}
\end{equation}
%

\bibliographystyle{naturemag}
\bibliography{bib}

\end{document}